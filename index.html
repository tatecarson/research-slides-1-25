<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" />
  <title>Big</title>
  <style>
    .responsive-iframe {
      position: absolute;
      top: 0;
      left: 0;
      bottom: 0;
      right: 0;
      width: 100%;
      height: 100%;
      border: none;
    }

    .photo-credit {
      position: absolute;
      bottom: 10px;
      right: 10px;
      font-size: 16px;
    }
  </style>
  <link href="big.css" rel="stylesheet" type="text/css" />
  <link href="themes/brutalist-2.css" rel="stylesheet" type="text/css" />
  <script src="js/index-citations-global.js"></script>
  <script>
    function run() {
      IndexCitations({
        referenceId: "#citations",
      });

      const citations = document.querySelectorAll(".citationLink");
      // TODO: update this to be the last slide whenever you make it
      citations.forEach((citation) => (citation.href = "#53"));

      const ref = document.querySelectorAll("#citations cite");

      ref.forEach((reference) => {
        var el = document.createElement("span");
        el.innerHTML = '<a href="javascript:history.back()">&#8627;</a>';
        insertAfter(reference, el);
      });
    }

    if (document.readyState != "loading") {
      run();
    } else {
      document.addEventListener("DOMContentLoaded", run);
    }

    function insertAfter(referenceNode, newNode) {
      referenceNode.parentNode.insertBefore(
        newNode,
        referenceNode.nextSibling
      );
    }

    document.addEventListener('DOMContentLoaded', () => {
      const slides = document.querySelectorAll('body > div');
      const counters = document.querySelectorAll('.slide-count');

      counters.forEach((counter, index) => {
        counter.textContent = `${index + 1}/${slides.length}`;
      });
    });
  </script>
  <script src="big.js"></script>
  <script src="js/lazysizes.min.js"></script>

</head>

<body class="light">

  <!-- Title slide  -->
  <div class="layout"
    style="grid-template-rows: repeat(5, minmax(0, 1fr)); grid-template-columns: repeat(6, 1fr); gap: 10px; height: 100vh;">
    <!-- Main title -->
    <div style="grid-row: 1 / 2; grid-column: 1 / 7;">
      RESEARCH <br> AND CREATIVE WORK
    </div>

    <!-- Subtitle -->
    <!-- <div style="grid-row: 1 / 2; grid-column: 5 / 7;">2024</div> -->

    <!-- Description text -->
    <div style="grid-row: 3; grid-column: 2 / 6;"><span class="underline">From Participatory Mobile Music to
        Locative Sound Art</span></div>

    <!-- Author/presenter info -->
    <div style="grid-row: 5; grid-column: 1 / 4;">Tate Carson, PhD</div>
    <div style="grid-row: 5; grid-column: 4 / 7;">Assistant Professor of Digital Sound Design</div>
    <notes>
      Introduction; mobile music and locative sound art with smartphones.

    </notes>
    <div class="slide-count"></div>

  </div>

  <div
    style="display: grid; grid-template-rows: repeat(6, 1fr); grid-template-columns: repeat(6, 1fr); gap: 5px; height:100vh ">
    <!-- Main title that establishes the topic -->
    <div style="grid-row: 1 / 3; grid-column: 1 / 7;">THE SMARTPHONE AS ARTISTIC PLATFORM</div>

    <!-- Core aspects in a structured layout -->
    <div style="grid-row: 3 / 4; grid-column: 2 / 4;"><span class="border">UBIQUITY</span></div>
    <div class="underline" style="grid-row: 3 / 4; grid-column: 6 / 7;">Open access</div>

    <div style="grid-row: 4 / 5; grid-column: 1 / 3;"><span class="border">SENSORS</span></div>
    <div class="underline" style="grid-row: 4 / 5; grid-column: 4 / 8;">GPS, gyroscope, microphone integration</div>

    <div style="grid-row: 6 / 7; grid-column: 2 / 4;"><span class="border">NETWORKS</span></div>
    <div class="underline" style="grid-row: 6/7; grid-column: 5 / 8;">Distributed and collaborative music-making</div>

    <!-- Bottom row emphasizing the broader impact -->
    <!-- <div style="grid-row: 6 / 7; grid-column: 1 / 7;">Transforming our relationship with sound, environment, and
      technology</div> -->

    <notes>
      A few things that make smartphones particularly interesting for music and sound art are their ubiquity, many
      people already have one in their pocket, the sensors that come with them, like GPS, gyroscope, and microphone, and
      the networks that they can connect to, allowing for the creation of collaborative digital musical experiences.

      These features allow for new ways of creating and experiencing music, and can transform our relationship with
      sound, environment, and technology.
    </notes>
    <div class="slide-count"></div>

  </div>

  <div class="layout" style="grid-template-rows: repeat(6, 1fr); grid-template-columns: repeat(8, 1fr); gap: 10px;">
    <div style="grid-row: 1 / 2; grid-column: 1 / 5;"><span class="underline">And the water receded</span></div>
    <div style="grid-row: 1 / 2; grid-column: 6;"><span class="border">2017</span></div>

    <!-- Second work aligned with the first for temporal connection -->
    <div style="grid-row: 2 / 3; grid-column: 4/7;"><span class="underline">A more perfect union</span></div>
    <div style="grid-row: 2 / 3; grid-column: 8;"><span class="border">2017</span></div>

    <div style="grid-row: 3; grid-column: 2 / 4;"><span class="underline">Mesh Garden</span></div>
    <div style="grid-row: 3; grid-column: 6;"><span class="border">2018</span></div>

    <!-- Middle period work spans wider, suggesting its duration -->
    <div style="grid-row: 4; grid-column: 1 / 4;"><span class="underline">Sounds Aware</span></div>
    <div style="grid-row: 4; grid-column: 4 / 7;"><span class="border">2019-2021</span></div>

    <!-- Recent works create dynamic tension through positioning -->
    <div style="grid-row: 5; grid-column: 3 / 6;"><span class="underline">immaterial.cloud</span></div>
    <div style="grid-row: 5; grid-column: 8;"><span class="border">2020</span></div>

    <!-- Latest work emphasized through full width -->
    <div style="grid-row: 6; grid-column: 2 / 5;"><span class="underline">Resonant Landscapes</span></div>
    <div style="grid-row: 6; grid-column: 6 / 8;"><span class="border">2023-Present</span></div>

    <notes>
      * I'll give an overview of the progression of my work over the past few years, starting with And the water receded
      in 2017, then moving on to A more perfect union, Mesh Garden, Sounds Aware, immaterial.cloud, and finally my most
      recent work Resonant
      Landscapes.

      * These works have explored different aspects of mobile music and locative sound art, and have built on
      each other to create a body of work that explores the potential of the smartphone as an artistic platform.
    </notes>
    <div class="slide-count"></div>

  </div>



  <div class="layout"
    style="grid-template-rows: repeat(6, minmax(0, 1fr)); grid-template-columns: repeat(6, 1fr); gap: 0px;">
    <!-- Primary title section takes full width at top with strong presence -->
    <div style="grid-row: 1 / 2; grid-column: 1 / 5;">
      <span class="underline">
        And the water receded

      </span>

    </div>
    <div style="grid-row: 1 / 2; grid-column: 7;">
      <span class="year">
        2017

      </span>
    </div>

    <!-- Core concept gets prominent secondary position -->
    <div style="grid-row: 2 / 3; grid-column: 2 / 6;">Sonification of Hurricane Katrina</div>

    <div style="grid-row: 3/6; grid-column:5/7">
      <img src="images/and-the-water.jpg" alt="">
    </div>

    <!-- Tools list indented and stacked -->
    <div style="grid-row: 4 / 6; grid-column: 2 / 5;">
      Networked Animated Notation
    </div>

    <div style="grid-row: 6 / 7; grid-column: 4 / 8;">Stepping Stone to Participatory Works &#8594;</div>
    <notes>
      *And the water receded* is a musical piece that sonifies Hurricane Katrina data for three performers and
      electronics, condensing the storm's timeline from formation to landfall. The work stems from the composer's
      personal hurricane experiences and uses animated smartphone-based notation to synchronize performers with
      electronics. The first movement, *And the waters returned*, transforms storm data (latitude, longitude, wind
      speed, and air pressure) into musical parameters, using saw waves and noise to reflect the storm's chaotic nature.
      The second movement, *What remained*, derives melodies from recovered family recipes. The piece employs
      **Rhizome** for OSC message distribution, data visualization through projected maps, and ambisonics for spatial
      audio representation. As a data-inspired composition, it balances artistic interpretation with scientific
      sonification, using natural patterns rather than random algorithms. Initially using smartphones only for score
      display, later adaptations employed them as distributed speakers when traditional multichannel systems weren't
      available, establishing groundwork for future smartphone-based musical works.
    </notes>
    <div class="slide-count"></div>

  </div>

  <div>

    <iframe class="responsive-iframe lazyload"
      src="https://www.youtube.com/embed/es_4M9t9K-4?si=N1-zD5QbFOD85nhW&amp;start=330" title="YouTube video player"
      frameborder="0"
      allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share"
      referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
    <div class="slide-count">

    </div>

  </div>

  <div class="layout"
    style="grid-template-rows: repeat(4, minmax(0, 1fr)); grid-template-columns: repeat(6, 1fr); gap: 10px;">
    <!-- Large hero image takes up most of the left side -->
    <div style="grid-row: 1 / 4; grid-column: 1 / 4;">
      <img src="images/ampu.png" />
    </div>

    <!-- Title and descriptive text on the right -->
    <div style="grid-row: 1 / 2; grid-column: 4 / 7;">
      <span class="underline">A more perfect union</span>
    </div>

    <!-- Exhibition details -->
    <div style="grid-row: 3 / 4; grid-column: 4 / 7;">
      Direct Audience Control
    </div>

    <!-- Footer information spans full width -->
    <div style="grid-row: 4 / 5; grid-column: 1 / 3;">
      <span class="year">2017</span>
    </div>
    <div style="grid-row: 4 / 5; grid-column: 3 / 7;">
      Smartphone Speaker Array
    </div>

    <notes>
      A More Perfect Union was conceived as a direct response to the limitations of And the Water Receded, exploring
      innovative approaches to creating and experiencing music on smartphones. Utilizing a smartphone speaker array, the
      work provided an immersive and interactive experience for the audience, serving as a precursor to subsequent
      participatory compositions. Guided by audience evaluations, melodies evolved through a genetic algorithm,
      ultimately culminating in an emergent sound that reflected collective preferences.
    </notes>
    <div class="slide-count"></div>

  </div>

  <div>
    <iframe title="vimeo-player" class="responsive-iframe lazyload" src="https://player.vimeo.com/video/267062963"
      frameborder="0" allowfullscreen></iframe>
    <notes>This is a performance version of the work that took place at LSU Museum
      of Art on March 4, 2018</notes>
    <div class="slide-count"></div>

  </div>

  <div>
    <div>Breaking the Audience / Performer Divide</div>
    <notes>
      * The audience transitions from passive listeners to active creators in *A more perfect union*, with all
      participants serving dual roles as both audience and performers, eliminating traditional performer-audience
      boundaries

      * Participation requires no musical expertise - audience members simply express preferences by choosing to listen
      to or skip melodies, making the work accessible while allowing them to drive its evolution

      * A genetic algorithm processes audience preferences in real-time, creating a feedback loop where collective
      choices directly shape the musical composition's development

      * The work functions as a conceptual experiment focused on collective creation rather than predetermined musical
      outcomes - participants don't need technical knowledge of the underlying algorithm to meaningfully contribute

      * The platform enables shared creation through audience interaction, fostering deeper connection as participants
      hear the composition develop through their collective input and preferences
    </notes>
    <div class="slide-count"></div>

  </div>
  <div class="layout" style="grid-template-rows: 75% 25%">
    <img src="./images/amoreperfectunion/League_FtM_perf.jpg" alt="" />

    <div>
      The League of Automatic Music Composers (Perkis, Horton, and Bischoff,
      left to right) performing at Ft. Mason, San Francisco 1981.
      <br />
    </div>
    <em class="photo-credit">photo: Peter Abramowitsch</em>

    <notes>A precursor to this concept of distributed control of a composition can
      be found in the early computer networked music groups The League of
      Automatic Music Composers and later The Hub. They created networks of
      computers that would send messages to other computers to create a rich
      texture of evolving sounds.
    </notes>
    <div class="slide-count"></div>

  </div>
  <div>
    <img src="./images/amoreperfectunion/sims-galapagos.jpg" alt="an image of Karl Sims' Galapagos installation" />

    <div>Karl Sims' Galapagos (1997)</div>

    <em class="photo-credit">photo: Ohtaka Takashi</em>
    <notes>
      Another important conceptual precursor to the work is Karl Sims' 1997
      installation Galapagos. Sims' work consisted of several video screens,
      each displaying a different virtual organism. The installation allowed
      spectators to take part in evolving virtual organisms by choosing the
      amount of time they spent in front of one video screen versus another.
      The longer a viewer stood in front of a screen, the more he increased
      the fitness of that virtual organism, and made it more likely for the
      organism to pass its traits onto the next generation.
    </notes>
    <div class="slide-count"></div>

  </div>

  <!-- <div class="layout">
    <div>
      <ul>
        <li>
          The inner workings of the genetic algorithm are opaque to the
          participants, more visualization could help.
        </li>
        <li>The work might be better as an installation.</li>
        <li>
          There are more creative possibilities with rhythmic synchronization.
        </li>
      </ul>

    </div>

    <div class="slide-count"></div>

  </div> -->





  <div class="layout"
    style="display: grid; grid-template-rows: repeat(4, 1fr); grid-template-columns: repeat(6, 1fr); gap: 10px;">
    <!-- Central image -->
    <div style="grid-row: 2 / 4; grid-column: 2 / 5;">
      <img src="images/mesh-garden-2.png" style="width: 100%; height: 100%;" alt="Featured image" />
    </div>

    <!-- Surrounding text -->
    <div style="grid-row: 1 / 2; grid-column: 1 / 7;"><span class="underline">Mesh Garden</span></div>
    <div style="grid-row: 2 / 4; grid-column: 1 / 2;"><span class="year">2018</span></div>
    <div style="grid-row: 2 / 4; grid-column: 5 / 7;">Musical Game</div>
    <div style="grid-row: 4 / 5; grid-column: 1 / 3;">Gyroscope</div>
    <div style="grid-row: 4 / 5; grid-column: 5 / 7;">Party Music</div>

    <notes>
      * *Mesh Garden* is a participatory music piece using smartphones as speakers/controllers in social settings, where
      players interact through orientation-based movements to create ambient music via a web interface

      * The system enables creative musical interaction through phone orientation and compass heading matching - when
      phones face each other, players can trade notes, fostering non-competitive creative orchestration

      * Players are assigned either long bowed or short percussive sounds, with technical implementation using Web Audio
      API, Tone.js, Socket.io, and Ableton Link for device synchronization

      * The piece builds on previous works by moving performance to casual social spaces and increasing player agency,
      while maintaining accessibility for non-musicians through game mechanics

      * Player feedback indicated engagement with the musical creation process, though some developed aggressive
      note-stealing strategies, suggesting potential future improvements for balancing experienced and new player
      experiences
    </notes>
    <div class="slide-count"></div>

  </div>

  <div>
    <iframe class="responsive-iframe azyload" src="https://www.youtube.com/embed/_WQHdGdvO2E" frameborder="0"
      allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
      allowfullscreen></iframe>

    <notes>
      Here's a video of the piece in action. The video shows a group of people playing the game, interacting with each
      other.

    </notes>
    <div class="slide-count"></div>

  </div>

  <div class="layout" style="grid-template-rows: 75% 25%">
    <img src="images/mesh-garden/Guitar-GH3-hammeron.0.webp" alt="" />
    <div>Guitar Hero</div>
    <div class="credit">
      <em class="photo-credit"> Photo: <a href="https://polygon.com">polygon.com</a></em>

    </div>
    <notes>
      * *Mesh Garden* is a creative-based musical game focused on generating original music through player interaction,
      contrasting with mimicry games like *Guitar Hero* which recreate existing songs

      * Core gameplay involves musical decision-making through phone orientation and player interaction, with mechanics
      designed for creating new music rather than reproducing predetermined scores

      * Following Thomas Studley's framework, *Mesh Garden* meets creative-based game criteria: gameplay centers on
      musical decisions, players directly influence music production, and actions are framed as creating new music

      * The game emphasizes social meaning through collaborative creation, similar to folk music traditions, whereas
      mimicry games focus on individual performance accuracy

      * Key distinction lies in originality vs. reproduction - *Mesh Garden* facilitates emergent, unique compositions
      through player choice and collaboration, while *Guitar Hero* values accurate reproduction of existing music
    </notes>
    <div class="slide-count"></div>

  </div>
  <div class="layout" style="grid-template-rows: 75% 25%">
    <img src="images/mesh-garden/instantcity_play.jpg" alt="" />
    <div style="font-size: 1.5em">Instant City (2003-2006)</div>
    <div>
      <div class="credit">
        <em class="photo-credit">Photo: <a
            href="http://www.hauert-reichmuth.ch/en/projekte/instant-city/">http://www.hauert-reichmuth.ch/en/projekte/instant-city/</a></em>

      </div>
    </div>
    <notes>
      * *Instant City* is a music-building game using blocks on a light table that translates block configurations into
      music, featuring ambient gameplay focused on exploration without predetermined goals

      * Like *Mesh Garden*, it emphasizes exploratory musical creation through player interaction, but differs in
      requiring specialized equipment (light table) versus *Mesh Garden's* accessible smartphone interface

      * *Mesh Garden* drew inspiration from *Instant City's* ambient gameplay style and interactive music creation,
      while improving accessibility through web-based mobile technology

      * Key technological differences: *Instant City* uses physical blocks and light table detection, while *Mesh
      Garden* employs Web Audio API, Tone.js, socket.io, and Ableton Link

      * While both focus on exploratory music-making, *Mesh Garden* innovates through orientation-based controls and
      note-trading mechanics versus *Instant City's* block arrangement system
    </notes>
    <div class="slide-count"></div>

  </div>


  <!-- <div class="layout" style="
        display: grid;
        grid-template-columns: repeat(4, 1fr);
        grid-template-rows: repeat(6, 1fr);
      ">
    <div style="grid-area: 1 / 1 / 2 / 5; justify-content: center;">
      <h1>Conclusions</h1>
    </div>
    <div style="grid-area: 2 / 1 / 5 / 5;">
      <ul>
        <li>Synchronization is difficult but useful</li>
        <li>Game dynamics open possibilities for participation</li>
        <li>
          More advanced interfaces needed for skilled musicians.
        </li>
      </ul>
    </div>

    <notes>
      * Key technical innovation of *Mesh Garden* lies in synchronization through Web Audio API, Tone.js, socket.io, and
      Ableton Link, enabling distributed sequencing across networks with metrical quantization for smooth timing

      * Game mechanics enable broad participation through intuitive phone orientation controls and note-trading,
      following Thomas Turino's participatory performance model where all are "players" rather than "audience"

      * Current design successfully enables non-musicians to contribute, but lacks advanced interfaces for skilled
      musicians - future versions may need skill-testing mechanisms and additional control layers

      * The indeterminate nature of the music and broad accessibility mirror folk traditions, though this may impact the
      emergence of flow states for experienced players

      * Development focus: balancing accessibility with advanced musical interaction - maintaining simple entry points
      while adding features for skilled players to develop mastery
    </notes>
    <div class="slide-count"></div>

  </div> -->

  <!-- Sounds Aware -->
  <div class="layout"
    style="grid-template-rows: repeat(4, minmax(0, 1fr)); grid-template-columns: repeat(6, 1fr); gap: 10px;">
    <!-- Large hero image takes up most of the left side -->

    <!-- Title and descriptive text on the right -->
    <div style="grid-row: 1 / 2; grid-column: 1 / 4;">
      <span class="underline">Sounds Aware</span>
    </div>

    <!-- Exhibition details -->
    <div style="grid-row: 3 / 4; grid-column: 1/4;">
      Locative Audio Sound Art
    </div>

    <div style="grid-row: 1 / 4; grid-column: 4/ 7;">
      <img src="images/sounds-aware.png" />
    </div>


    <!-- Footer information spans full width -->
    <div style="grid-row: 4 / 5; grid-column: 1 / 3;">
      <span class="year">2019 — 2021</span>
    </div>
    <div style="grid-row: 4 / 5; grid-column: 3 / 7;">
      An app for sharing sound walks
    </div>

    <notes>
      After Mesh Garden, I became interested in leveraging the mobility of smartphones to create experiences designed
      for outdoor environments and walking. This led to Sounds Aware, a locative audio sound art project that fostered a
      shared experience of the environment through sound. Developed as a web app, the project enabled users to share
      sound walks, creating a collective soundscape that reflected the diversity of their surroundings. Running from
      2019 to 2021, Sounds Aware explored the potential of locative audio as a medium for crafting shared environmental
      experiences.
    </notes>
    <div class="slide-count"></div>

  </div>

  <div class="fancy-quote">
    <blockquote>

      To what extent might the technologies of communication, art and
      entertainment serve as 'prostheses' that would provide us with
      experiences of wilderness that would not only enrich our human
      identity but help us to preserve and expand the domain of the
      non-human world?

      <cite>
        David Dunn. Wilderness as Reentrant Form: Thoughts on the Future of
        Electronic Art and Nature. Leonardo, (4):377, 1988.
      </cite>
    </blockquote>
    <div style="text-align: right;">- David Dunn</div>

    <notes>
      * Composer and artist, David Dunn proposes that communication and art technologies can serve as "prostheses" to
      connect people with wilderness experiences, viewing this as essential since not everyone can access natural spaces
      directly

      * Sounds Aware exemplifies technology as a "prosthesis" for experiencing wilderness by using smartphones to
      connect users with natural soundscapes through sound walks, active listening, and decentralized sharing. The app
      focuses on restoring attention and fostering ecological awareness by helping users overcome "numbed ears" and
      rediscover natural sounds in their environment. It transforms survey data about restorative experiences into
      shareable sonifications, creating a collective tool for deeper engagement with nature.

      * immaterial.cloud explores using peer-to-peer technology to create shared experiences and counter isolation,
      showing how technology can foster meaningful interconnection

      * Resonant Landscapes overlays natural soundscapes onto urban spaces using GPS, creating hybrid experiences that
      encourage users to discover nature in familiar places

      * Environmental artists like Truax, Westerkamp, and Barclay use sound art and interactive technology to raise
      ecological awareness and encourage sustainable behavior through direct engagement

      * While these technological prostheses don't replace direct nature experiences, they can enhance environmental
      understanding, shift perceptions, and motivate conservation efforts
    </notes>
    <div class="slide-count"></div>

  </div>


  <div class="layout">
    <img src="images/sounds-aware-v2/ui-1.png" alt="" />

    <notes>
      * Sounds Aware enables users to create and share sound walks by answering survey questions about the
      restorativeness of specific locations

      * The app converts survey responses into wind chime-like sonifications that other users hear when following the
      same walk

      * It uses decentralized technology (IPFS, 3Box) to manage user data, resisting the attention economy of
      traditional social media
    </notes>
    <div class="slide-count"></div>

  </div>

  <div class="layout">
    <img src="images/sounds-aware-v2/ui-2.png" alt="" />

    <notes>
      * The app focuses on restoration of attention and ecological awareness by encouraging mindful listening and
      outdoor
      experiences

      * Users must be physically present to create or experience walks, promoting direct engagement with natural
      environments
    </notes>
    <div class="slide-count"></div>

  </div>

  <!-- immaterial.cloud -->
  <div class="layout"
    style="grid-template-rows: repeat(4, minmax(0, 1fr)); grid-template-columns: repeat(6, 1fr); gap: 10px;">
    <!-- Large hero image takes up most of the left side -->
    <div style="grid-row: 1 / 4; grid-column: 1 / 4;">
      <img src="images/immaterial.png" />
    </div>

    <!-- Title and descriptive text on the right -->
    <div style="grid-row: 1 / 2; grid-column: 4 / 7;">
      <span class="underline">immaterial.cloud</span>
    </div>

    <!-- Exhibition details -->
    <div style="grid-row: 3 / 4; grid-column: 4 / 7;">
      Collaborative Sound Art
    </div>

    <!-- Footer information spans full width -->
    <div style="grid-row: 4 / 5; grid-column: 1 / 3;">
      <span class="year">2020</span>
    </div>
    <div style="grid-row: 4 / 5; grid-column: 3 / 7;">
      peer-to-peer networking
    </div>

    <notes>
      For this project, I revisited the concept of collaborative music-making with smartphones, this time exploring the
      use of the phone's camera as a trigger for changes in sound. Networked smartphones formed a temporary sound art
      installation that could be set up anywhere, activating sound by flipping phones upward to allow the camera to
      detect movement. immaterial.cloud was a collaborative sound art project that harnessed peer-to-peer networking to
      create and share music. Designed as a collective experience, participants contributed to a shared soundscape,
      leveraging smartphone networking capabilities to facilitate a dynamic, interactive musical installation that
      transcended traditional boundaries of time and space.
    </notes>
    <div class="slide-count"></div>

  </div>

  <div class="layout" style="grid-template-rows: 75% 25%">
    <img src="images/immaterialcloud2.png" alt="immaterial.cloud" />
    <div>Participants interacting with the work</div>
    <notes>
      * Immaterial.cloud is a web app using peer-to-peer technology (WebRTC) to create shared experiences, developed
      during COVID-19 isolation
      * Users interact through motion (tracked by phone cameras), which triggers shared sound changes across connected
      devices
      * Unlike traditional social media, it aims for deep attention and collective experience rather than profiting from
      user attention
      * Phones connect through a host device using broadcast methods, with each device assigned one of four presets
      using granular synthesis

    </notes>
    <div class="slide-count"></div>

  </div>


  <div class="layout" style="grid-template-rows: 75% 25%">
    <img src="images/immaterialcloud/qi5jxtMLvuyjoAfMFJ6onDzEUQptFfu8cggWfDfms3Q.png" alt="" />
    <a href="https://immaterial.cloud" target="blank">https://immaterial.cloud</a>

    <notes>
      This work needs 2-4 smartphones (iPhone or Android) connected to the
      internet via WiFi or a cellular network. All sound during the
      installation is played over the phones. A participant joins the network
      by going to <https: //immaterial.cloud> and entering the ID of a chosen
        "host" phone. No extra software is required to participate.
        immaterial.cloud will work with a group of participants or just one.
    </notes>
    <div class="slide-count"></div>

  </div>

  <div>
    <iframe title="vimeo-player" class="responsive-iframe azyload" src="https://player.vimeo.com/video/414630388"
      frameborder="0" allowfullscreen></iframe>
    <div class="slide-count"></div>

  </div>

  <!-- Resonant Landscapes -->
  <div class="layout"
    style="display: grid; grid-template-rows: repeat(4, 1fr); grid-template-columns: repeat(6, 1fr); gap: 10px;">
    <!-- Central image -->
    <div style="grid-row: 2 / 4; grid-column: 2 / 5;">
      <img src="images/frozen-lake.jpeg" style="width: 100%; height: 100%;" alt="Featured image" />
    </div>

    <!-- Surrounding text -->
    <div style="grid-row: 1 / 2; grid-column: 1 / 7;"><span class="underline">Resonant Landscapes</span></div>
    <div style="grid-row: 2 / 4; grid-column: 1 / 2;"><span class="year">2023-Present</span></div>
    <div style="grid-row: 2 / 4; grid-column: 5 / 7;">Locative Sound Art</div>
    <div style="grid-row: 4 / 5; grid-column: 1 / 3;">Ambisonic Field Recording</div>
    <div style="grid-row: 4 / 5; grid-column: 5 / 7;">GPS/Gyroscope</div>

    <notes>
      Resonant Landscapes is my most recent work, and it builds on the concepts explored in my previous projects. The
      piece uses ambisonic field recordings to create an immersive sound environment that responds to the listener's
      movement through space. By integrating GPS and gyroscope data from smartphones, the work transforms the listener's
      surroundings into a dynamic, interactive soundscape, inviting them to explore the sonic possibilities of their
      environment.
    </notes>
    <div class="slide-count"></div>

  </div>

  <div>

    <em><strong>Resonant Landscapes</strong></em> creates a <strong>hybrid place</strong>, merging natural
    soundscapes with urban spaces through <strong>ambisonic audio</strong> and GPS technology.

    <notes>
      Creating a Hybrid Place:

      - Locative Media: Maps state park coordinates onto DSU campus locations, creating a scaled geographical
      representation.
      - Ambisonic Audio: Plays immersive soundscapes when users approach designated spots.
      - Hybrid Soundscapes: Combines recorded nature sounds with real-time environmental sounds.
      - Body-Oriented Tracking: Uses smartphone sensors (GPS, gyroscope, accelerometer) for dynamic sound orientation.
      - Non-Representational Sound: Encourages immersion through abstract, non-representational soundscapes.

      Theoretical Influences:
      - Draws from sound art, soundwalking, and soundscape studies.
      - Resituates soundscapes in urban settings to encourage reflection on:
      - Ecological significance.
      - Cultural importance.
      - Relationship between sound, nature, and urban life.

      Experience & Impact:

      - Creates a "hybrid place" blending virtual and physical realities.
      - Induces a contemplative, reflective state, offering an escape from daily worries.
      - Challenges traditional notions of music and art through immersive, dynamic soundscapes.
    </notes>
    <div class="slide-count"></div>
  </div>

  <div class="layout" style="grid-template-rows: 75% 25%">
    <img src="images/rl-screenshots/me-carter.png" alt="">

    <div>Student Research</div>

    <notes>
      Resonant Landscapes was developed in collaboration with a student at Dakota State University. The project provided
      an opportunity to engage with cutting-edge technologies and explore the creative possibilities of locative sound
      art. Through their research and experimentation, my student contributed to the development of the app and helped
      shape its features.
    </notes>
    <div class="slide-count"></div>

  </div>


  <div class="layout" style="grid-template-rows: 75% 25%">
    <img src="images/rl-screenshots/sd-state-parks.png">
    <div>South Dakota State Parks</div>
    <div class="slide-count"></div>

    <notes>
      You can see in this picture all of the state parks we recorded at. Carter was integral to this project, as I would
      not have been able to record all of these locations without his help.
    </notes>
  </div>


  <div class="layout" style="grid-template-rows: 75% 25%">
    <img src="images/rl-screenshots.png" alt="">

    <div>User Interactions</div>

    <notes>
      * Resonant Landscapes' audience webpage provides an interactive campus map with marked "listening spots" that
      correspond to state park locations

      * Users experience audio playback within 15-meter radius zones, with volume increasing as they approach centers

      * Visual feedback includes falling leaves animation that speeds up with proximity

      * The app uses smartphone sensors for body-oriented tracking, letting users change soundscape orientation by
      turning physically

      * The web-based interface requires no downloads, creating a hybrid space by overlaying natural soundscapes onto
      the campus environment
    </notes>
    <div class="slide-count"></div>

  </div>



  <div class="layout" style="
                grid-template-columns: repeat(4, 1fr);
                grid-template-rows: repeat(5, 1fr);
              ">
    <div style="grid-area: 1 / 1 / 3 / 6; justify-content: center">
      <h1>Technical Details</h1>
    </div>
    <div style="grid-area:  3 / 1 / 6 / 3">
      <ul>
        <li>Core Audio OctoMic</li>
        <li>Web tech: React, Tailwind CSS, Resonance Audio SDK</li>
        <li>Smartphone sensors: GPS, gyroscope, accelerometer</li>

      </ul>
    </div>
    <div style="grid-area:3 / 3 / 6 / 5">
      <img src="images/octomic.jpg" width="100%" alt="" />
    </div>

    <notes>
      * The project uses a Core Audio OctoMic for 2nd-order ambisonic recording and Resonance Audio SDK for spatial
      audio processing

      * Built with React and Tailwind CSS, utilizing smartphone GPS for location tracking and gyroscope/accelerometer
      for body-oriented listening

      * Key libraries include:
      - Omnitone for ambisonic audio handling
      - Three.js for 3D calculations
      - Turf.js for geospatial analysis
      - rLayers for map functionality

      * Follows frugal innovation principles by leveraging existing smartphone sensors and web technologies

      * Creates hybrid spaces by combining proximal soundscapes with users' physical locations
    </notes>
    <div class="slide-count"></div>

  </div>

  <div class="layout">

    Resonant Landscapes Concert

    <notes>
      In addition to using the ambisonic recordings in the Resonant Landscapes app, DSU faculty and students composed
      works that premiered during a public concert at the Madison Area Arts Council.
    </notes>
    <div class="slide-count"></div>

  </div>


  <div class="layout">

    <img src="images/rl-concert/landscape-poster.png" alt="" width="100%" height="500px">

    <notes>
      In addition to using the ambisonic recordings in the Resonant Landscapes app, DSU faculty and students composed
      works that premiered during a public concert at the Madison Area Arts Council.
    </notes>
    <div class="slide-count"></div>

  </div>

  <div style="display: flex; justify-content: space-between;">

    <img src="images/rl-concert/me.png" alt="" style="width: 48%;">
    <img src="images/rl-concert/daniel.png" alt="" style="width: 48%;">

    <notes>
      In addition to using the ambisonic recordings in the Resonant Landscapes app, DSU faculty and students composed
      works that premiered during a public concert at the Madison Area Arts Council.
    </notes>
    <div class="slide-count"></div>

  </div>

  <div>

    <img src="images/rl-concert/kayla.png" alt="">

    <notes>
      In addition to using the ambisonic recordings in the Resonant Landscapes app, DSU faculty and students composed
      works
      that premiered during a public concert at the Madison Area Arts Council.
    </notes>
    <div class="slide-count"></div>

  </div>

  <div>

    <img src="images/rl-concert/jacob.png" alt="">

    <notes>
      In addition to using the ambisonic recordings in the Resonant Landscapes app, DSU faculty and students composed
      works
      that premiered during a public concert at the Madison Area Arts Council.
    </notes>
    <div class="slide-count"></div>

  </div>

  <div
    style="display: grid; grid-template-rows: repeat(4, minmax(0, 1fr)); grid-template-columns: repeat(6, 1fr); gap: 10px; height: 100vh;">
    <!-- Dominant visual element -->
    <div style="grid-row: 1 / 4; grid-column: 1 / 4;"><span class="underline">Veins of</span></div>
    <div style="grid-row: 2 / 3; grid-column: 1 / 4;"><span class="underline">the Earth</span></div>

    <!-- Information block -->
    <div style="grid-row: 3 / 4; grid-column: 4 / 7;">Fixed</div>

    <!-- Footer information -->
    <div style="grid-row: 4 / 5; grid-column: 4/7;">Media</div>
    <div style="grid-row: 4 / 5; grid-column: 1;"><span class="year">2024</span></div>

    <!-- Soundcloud Player -->
    <div class="soundcloud-embed" style="grid-row: 1 / 3; grid-column: 4 / 7; align-self: center;">
      <iframe width="100%" height="166" scrolling="no" frameborder="no" allow="autoplay"
        src="https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/1833817539&color=%233c7494&auto_play=false&hide_related=false&show_comments=true&show_user=true&show_reposts=false&show_teaser=true">
      </iframe>
    </div>
    <notes>
      The work I composed for this concert was a multi-channel fixed media piece, “Veins of the Earth,” which explores
      geophonic and biophonic sounds to evoke a sense of connection between natural environments and the life they
      sustain.
    </notes>
    <div class="slide-count"></div>

  </div>

  <div class="layout" style="grid-template-rows: 75% 25%">
    <img src="images/rl-screenshots/uni-mi.png">
    <div>Resonant Landscapes @ UniMi</div>
    <div class="slide-count"></div>
    <notes>
      * As locative media art rather than site-specific art, Resonant Landscapes can be deployed anywhere by mapping
      state park coordinates onto new locations
    </notes>
  </div>

  <!-- Impact statement gets strong position at bottom -->
  <div
    style="display: grid; grid-template-rows: repeat(4, minmax(0, 1fr)); grid-template-columns: repeat(6, 1fr); gap: 0px; height: 100vh;">
    <!-- Large visual element -->
    <div style="grid-row: 1 / 3; grid-column: 1 / 4;">FUTURE </div>

    <!-- Contrasting text blocks -->
    <div style="grid-row: 1 / 2; grid-column: 3 / 7;">WORK</div>
    <div style="grid-row: 2 / 3; grid-column: 4 / 7;"><span class="underline">South Dakota Sound Archive</span></div>

    <!-- Information hierarchy -->
    <div style="grid-row: 3 / 5; grid-column: 1 / 3;"><span class="year">2025</span></div>
    <div style="grid-row: 3 / 4; grid-column: 3 / 7;">Student Work</div>
    <div style="grid-row: 4 / 5; grid-column: 3 / 7;">Community Engagement</div>
    <notes>
      My future research focuses on creating the DSU Digital Sound Archive, a project designed to capture the ecological
      soundscapes and cultural heritage of South Dakota and nearby regions. By integrating advanced field recording
      techniques and metadata, the archive will support interdisciplinary research across sound studies, ecology, and
      digital arts. A key component of the project is the Resonant Landscapes app, which uses GPS technology to overlay
      soundscapes onto physical locations, enhancing public engagement and ecological awareness. This initiative aligns
      with DSU's mission to expand research opportunities and foster collaboration across disciplines.
    </notes>
    <div class="slide-count"></div>

  </div>
  <div class=layout style='grid-template-columns: 50% 50%;'>
    <div>Questions?</div>
    <div>tatecarson.com tate.carson@pm.me</div>
    <div class="slide-count"></div>

  </div>


</body>

</html>