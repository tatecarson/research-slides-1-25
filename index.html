<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" />
  <title>Big</title>
  <style>
    .responsive-iframe {
      position: absolute;
      top: 0;
      left: 0;
      bottom: 0;
      right: 0;
      width: 100%;
      height: 100%;
      border: none;
    }

    .photo-credit {
      position: absolute;
      bottom: 10px;
      right: 10px;
      font-size: 16px;
    }
  </style>
  <link href="big.css" rel="stylesheet" type="text/css" />
  <link href="themes/brutalist-2.css" rel="stylesheet" type="text/css" />
  <script src="js/index-citations-global.js"></script>
  <script>
    function run() {
      IndexCitations({
        referenceId: "#citations",
      });

      const citations = document.querySelectorAll(".citationLink");
      // TODO: update this to be the last slide whenever you make it
      citations.forEach((citation) => (citation.href = "#53"));

      const ref = document.querySelectorAll("#citations cite");

      ref.forEach((reference) => {
        var el = document.createElement("span");
        el.innerHTML = '<a href="javascript:history.back()">&#8627;</a>';
        insertAfter(reference, el);
      });
    }

    if (document.readyState != "loading") {
      run();
    } else {
      document.addEventListener("DOMContentLoaded", run);
    }

    function insertAfter(referenceNode, newNode) {
      referenceNode.parentNode.insertBefore(
        newNode,
        referenceNode.nextSibling
      );
    }

    document.addEventListener('DOMContentLoaded', () => {
      const slides = document.querySelectorAll('body > div');
      const counters = document.querySelectorAll('.slide-count');

      counters.forEach((counter, index) => {
        counter.textContent = `${index + 1}/${slides.length}`;
      });
    });
  </script>
  <script src="big.js"></script>
  <script src="js/lazysizes.min.js"></script>

</head>

<body class="light">

  <!-- Title slide  -->
  <div class="layout"
    style="grid-template-rows: repeat(5, minmax(0, 1fr)); grid-template-columns: repeat(6, 1fr); gap: 10px; height: 100vh;">
    <!-- Main title -->
    <div style="grid-row: 1 / 2; grid-column: 1 / 7;">
      RESEARCH <br> AND CREATIVE WORK
    </div>

    <!-- Subtitle -->
    <!-- <div style="grid-row: 1 / 2; grid-column: 5 / 7;">2024</div> -->

    <!-- Description text -->
    <div style="grid-row: 3; grid-column: 2 / 6;"><span class="underline">From Participatory Mobile Music to
        Locative Sound Art</span></div>

    <!-- Author/presenter info -->
    <div style="grid-row: 5; grid-column: 1 / 4;">Tate Carson</div>
    <div style="grid-row: 5; grid-column: 4 / 7;">Assistant Professor of Digital Sound Design</div>
    <notes>
      Introduction; mobile music and locative sound art with smartphones.

    </notes>
    <div class="slide-count"></div>

  </div>

  <div
    style="display: grid; grid-template-rows: repeat(6, 1fr); grid-template-columns: repeat(6, 1fr); gap: 5px; height:100vh ">
    <!-- Main title that establishes the topic -->
    <div style="grid-row: 1 / 3; grid-column: 1 / 7;">THE SMARTPHONE AS ARTISTIC PLATFORM</div>

    <!-- Core aspects in a structured layout -->
    <div style="grid-row: 3 / 4; grid-column: 2 / 4;"><span class="border">UBIQUITY</span></div>
    <div class="underline" style="grid-row: 3 / 4; grid-column: 6 / 7;">Open access</div>

    <div style="grid-row: 4 / 5; grid-column: 1 / 3;"><span class="border">SENSORS</span></div>
    <div class="underline" style="grid-row: 4 / 5; grid-column: 4 / 8;">GPS, gyroscope, microphone integration</div>

    <div style="grid-row: 5 / 6; grid-column: 2 / 4;"><span class="border">NETWORKS</span></div>
    <div class="underline" style="grid-row: 5 / 6; grid-column: 5 / 8;">Distributed and collaborative music-making</div>

    <!-- Bottom row emphasizing the broader impact -->
    <div style="grid-row: 6 / 7; grid-column: 1 / 7;">Transforming our relationship with sound, environment, and
      technology</div>

    <notes>
      A few things that make smartphones particularly interesting for music and sound art are their ubiquity, many
      people already have one in their pocket, the sensors that come with them, like GPS, gyroscope, and microphone, and
      the networks that they can connect to, allowing for the creation of collaborative digital musical experiences.

      These features allow for new ways of creating and experiencing music, and can transform our relationship with
      sound, environment, and technology.
    </notes>
    <div class="slide-count"></div>

  </div>

  <div class="layout" style="grid-template-rows: repeat(6, 1fr); grid-template-columns: repeat(8, 1fr); gap: 10px;">
    <div style="grid-row: 1 / 2; grid-column: 1 / 5;"><span class="underline">And the water receded</span></div>
    <div style="grid-row: 1 / 2; grid-column: 6;"><span class="border">2017</span></div>

    <!-- Second work aligned with the first for temporal connection -->
    <div style="grid-row: 2 / 3; grid-column: 4/7;"><span class="underline">A more perfect union</span></div>
    <div style="grid-row: 2 / 3; grid-column: 8;"><span class="border">2017</span></div>

    <div style="grid-row: 3; grid-column: 2 / 4;"><span class="underline">Mesh Garden</span></div>
    <div style="grid-row: 3; grid-column: 6;"><span class="border">2018</span></div>

    <!-- Middle period work spans wider, suggesting its duration -->
    <div style="grid-row: 4; grid-column: 1 / 4;"><span class="underline">Sounds Aware</span></div>
    <div style="grid-row: 4; grid-column: 4 / 7;"><span class="border">2019-2021</span></div>

    <!-- Recent works create dynamic tension through positioning -->
    <div style="grid-row: 5; grid-column: 3 / 6;"><span class="underline">immaterial.cloud</span></div>
    <div style="grid-row: 5; grid-column: 8;"><span class="border">2020</span></div>

    <!-- Latest work emphasized through full width -->
    <div style="grid-row: 6; grid-column: 2 / 5;"><span class="underline">Resonant Landscapes</span></div>
    <div style="grid-row: 6; grid-column: 6 / 8;"><span class="border">2023-2024</span></div>

    <notes>
      * I'll give an overview of the progression of my work over the past few years, starting with And the water receded
      in 2017, then moving on to A more perfect union, Mesh Garden, Sounds Aware, immaterial.cloud, and finally my most
      recent work Resonant
      Landscapes.

      * These works have explored different aspects of mobile music and locative sound art, and have built on
      each other to create a body of work that explores the potential of the smartphone as an artistic platform.
    </notes>
    <div class="slide-count"></div>

  </div>



  <div class="layout"
    style="grid-template-rows: repeat(6, minmax(0, 1fr)); grid-template-columns: repeat(6, 1fr); gap: 0px;">
    <!-- Primary title section takes full width at top with strong presence -->
    <div style="grid-row: 1 / 2; grid-column: 1 / 5;">
      <span class="underline">
        And the water receded

      </span>

    </div>
    <div style="grid-row: 1 / 2; grid-column: 7;">
      <span class="year">
        2017

      </span>
    </div>

    <!-- Core concept gets prominent secondary position -->
    <div style="grid-row: 2 / 3; grid-column: 2 / 6;">Sonification of Hurricane Katrina</div>

    <div style="grid-row: 3/6; grid-column:5/7">
      <img src="images/and-the-water.jpg" alt="">
    </div>

    <!-- Tools list indented and stacked -->
    <div style="grid-row: 4 / 6; grid-column: 2 / 5;">
      Networked Animated Notation
    </div>

    <div style="grid-row: 6 / 7; grid-column: 4 / 8;">Stepping Stone to Participatory Works &#8594;</div>
    <notes>
      *And the water receded* is a musical piece that sonifies Hurricane Katrina data for three performers and
      electronics, condensing the storm's timeline from formation to landfall. The work stems from the composer's
      personal hurricane experiences and uses animated smartphone-based notation to synchronize performers with
      electronics. The first movement, *And the waters returned*, transforms storm data (latitude, longitude, wind
      speed, and air pressure) into musical parameters, using saw waves and noise to reflect the storm's chaotic nature.
      The second movement, *What remained*, derives melodies from recovered family recipes. The piece employs
      **Rhizome** for OSC message distribution, data visualization through projected maps, and ambisonics for spatial
      audio representation. As a data-inspired composition, it balances artistic interpretation with scientific
      sonification, using natural patterns rather than random algorithms. Initially using smartphones only for score
      display, later adaptations employed them as distributed speakers when traditional multichannel systems weren't
      available, establishing groundwork for future smartphone-based musical works.
    </notes>
    <div class="slide-count"></div>

  </div>

  <div>
    <iframe class="responsive-iframe lazyload" src="https://www.youtube.com/embed/es_4M9t9K-4?si=1psU33t4fD6FsvEw"
      title="YouTube video player" frameborder="0" allowfullscreen></iframe>
    <div class="slide-count"></div>

  </div>

  <div class="layout"
    style="grid-template-rows: repeat(4, minmax(0, 1fr)); grid-template-columns: repeat(6, 1fr); gap: 10px;">
    <!-- Large hero image takes up most of the left side -->
    <div style="grid-row: 1 / 4; grid-column: 1 / 4;">
      <img src="images/ampu.png" />
    </div>

    <!-- Title and descriptive text on the right -->
    <div style="grid-row: 1 / 2; grid-column: 4 / 7;">
      <span class="underline">A more perfect union</span>
    </div>

    <!-- Exhibition details -->
    <div style="grid-row: 3 / 4; grid-column: 4 / 7;">
      Direct Audience Control
    </div>

    <!-- Footer information spans full width -->
    <div style="grid-row: 4 / 5; grid-column: 1 / 3;">
      <span class="year">2017</span>
    </div>
    <div style="grid-row: 4 / 5; grid-column: 3 / 7;">
      Smartphone Speaker Array
    </div>

    <notes>
      A More Perfect Union was conceived as a direct response to the limitations of And the Water Receded, exploring
      innovative approaches to creating and experiencing music on smartphones. Utilizing a smartphone speaker array, the
      work provided an immersive and interactive experience for the audience, serving as a precursor to subsequent
      participatory compositions. Guided by audience evaluations, melodies evolved through a genetic algorithm,
      ultimately culminating in an emergent sound that reflected collective preferences.
    </notes>
    <div class="slide-count"></div>

  </div>

  <div>
    <iframe title="vimeo-player" class="responsive-iframe lazyload" src="https://player.vimeo.com/video/267062963"
      frameborder="0" allowfullscreen></iframe>
    <notes>This is a performance version of the work that took place at LSU Museum
      of Art on March 4, 2018</notes>
    <div class="slide-count"></div>

  </div>

  <div>
    <div>Breaking the Audience / Performer Divide</div>
    <notes>
      * The audience transitions from passive listeners to active creators in *A more perfect union*, with all
      participants serving dual roles as both audience and performers, eliminating traditional performer-audience
      boundaries

      * Participation requires no musical expertise - audience members simply express preferences by choosing to listen
      to or skip melodies, making the work accessible while allowing them to drive its evolution

      * A genetic algorithm processes audience preferences in real-time, creating a feedback loop where collective
      choices directly shape the musical composition's development

      * The work functions as a conceptual experiment focused on collective creation rather than predetermined musical
      outcomes - participants don't need technical knowledge of the underlying algorithm to meaningfully contribute

      * The platform enables shared creation through audience interaction, fostering deeper connection as participants
      hear the composition develop through their collective input and preferences
    </notes>
    <div class="slide-count"></div>

  </div>
  <div class="layout" style="grid-template-rows: 75% 25%">
    <img src="./images/amoreperfectunion/League_FtM_perf.jpg" alt="" />

    <div>
      The League of Automatic Music Composers (Perkis, Horton, and Bischoff,
      left to right) performing at Ft. Mason, San Francisco 1981.
      <br />
    </div>
    <em class="photo-credit">photo: Peter Abramowitsch</em>

    <notes>A precursor to this concept of distributed control of a composition can
      be found in the early computer networked music groups The League of
      Automatic Music Composers and later The Hub. They created networks of
      computers that would send messages to other computers to create a rich
      texture of evolving sounds.
    </notes>
    <div class="slide-count"></div>

  </div>
  <div>
    <img src="./images/amoreperfectunion/sims-galapagos.jpg" alt="an image of Karl Sims' Galapagos installation" />

    <div>Karl Sims' Galapagos (1997)</div>

    <em class="photo-credit">photo: Ohtaka Takashi</em>
    <notes>
      Another important conceptual precursor to the work is Karl Sims' 1997
      installation Galapagos. Sims' work consisted of several video screens,
      each displaying a different virtual organism. The installation allowed
      spectators to take part in evolving virtual organisms by choosing the
      amount of time they spent in front of one video screen versus another.
      The longer a viewer stood in front of a screen, the more he increased
      the fitness of that virtual organism, and made it more likely for the
      organism to pass its traits onto the next generation.
    </notes>
    <div class="slide-count"></div>

  </div>

  <div class="layout" style="
        display: grid;
        grid-template-columns: repeat(4, 1fr);
        grid-template-rows: repeat(5, 1fr);
      ">
    <div style="grid-area: 1 / 1 / 2 / 5; justify-content: center;">
      <h1>Conclusions</h1>
    </div>
    <div style="grid-area: 2 / 1 / 5 / 5;">
      <ul>
        <li>
          The inner workings of the genetic algorithm are opaque to the
          participants, more visualization could help.
        </li>
        <li>The work might be better as an installation.</li>
        <li>
          There are more creative possibilities with rhythmic synchronization.
        </li>
      </ul>
    </div>
    <div class="slide-count"></div>

  </div>





  <div class="layout"
    style="display: grid; grid-template-rows: repeat(4, 1fr); grid-template-columns: repeat(6, 1fr); gap: 10px;">
    <!-- Central image -->
    <div style="grid-row: 2 / 4; grid-column: 2 / 5;">
      <img src="images/mesh-garden-2.png" style="width: 100%; height: 100%;" alt="Featured image" />
    </div>

    <!-- Surrounding text -->
    <div style="grid-row: 1 / 2; grid-column: 1 / 7;"><span class="underline">Mesh Garden</span></div>
    <div style="grid-row: 2 / 4; grid-column: 1 / 2;"><span class="year">2018</span></div>
    <div style="grid-row: 2 / 4; grid-column: 5 / 7;">Musical Game</div>
    <div style="grid-row: 4 / 5; grid-column: 1 / 3;">Gyroscope</div>
    <div style="grid-row: 4 / 5; grid-column: 5 / 7;">Party Music</div>

    <notes>
      After A More Perfect Union, I sought to explore composing for spaces beyond the concert hall, leading to the
      creation of Mesh Garden, a musical game that expanded on the smartphone's potential as a platform for creating and
      experiencing music. Utilizing smartphone gyroscopes, the work offered an interactive and immersive experience,
      designed specifically for parties and other social gatherings.
    </notes>
    <div class="slide-count"></div>

  </div>

  <div>
    <iframe class="responsive-iframe azyload" src="https://www.youtube.com/embed/_WQHdGdvO2E" frameborder="0"
      allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
      allowfullscreen></iframe>

    <notes>
      The work also has a gameplay aspect; if two players' phones match in
      orientation, one player has the option to take the other player's note,
      building up a bank of notes that will be used to form a melody.
      <br />
    </notes>
    <div class="slide-count"></div>

  </div>

  <div class="layout" style="grid-template-rows: 75% 25%">
    <img src="images/mesh-garden/Guitar-GH3-hammeron.0.webp" alt="" />
    <div>Guitar Hero</div>
    <div class="credit">
      <em class="photo-credit"> Photo: <a href="https://polygon.com">polygon.com</a></em>

    </div>
    <notes>
      You may think that this sounds similar to games like Guitar Hero but
      that would be considered mimicry, the object being recreation of music
      not the creation of something new. Thomas Studley gives a definition of
      creative-based musical games that requires the games to create some sort
      of new music, not just mimic as in karaoke.
    </notes>
    <div class="slide-count"></div>

  </div>
  <div class="layout" style="grid-template-rows: 75% 25%">
    <img src="images/mesh-garden/instantcity_play.jpg" alt="" />
    <div style="font-size: 1.5em">Instant City (2003-2006)</div>
    <div>
      <div class="credit">
        <em class="photo-credit">Photo: <a
            href="http://www.hauert-reichmuth.ch/en/projekte/instant-city/">http://www.hauert-reichmuth.ch/en/projekte/instant-city/</a></em>

      </div>
    </div>
    <notes>Many music games exist that fulfill all or part of Studley's definition
      for creative-based music games. Instant City1 is a music-building table
      game created by Sibylle Hauert and Daniel Reichmuth in collaboration
      with Volker Bohm. Players stack blocks on top of each other to create
      music. Mesh Garden is inspired by the ambient gameplay aspect of this
      work. Instant City has no specific gameplay or aesthetic goal; the
      gameplay mode is exploratory. While being an impressive project, it is
      not very accessible as it requires a unique light table to read where
      the blocks are positioned.
    </notes>
    <div class="slide-count"></div>

  </div>

  <div class="layout" style="grid-template-rows: 75% 25%">
    <img src="images/mesh-garden/Reactable_Multitouch.jpg" width="1000px""
      alt="" />
      <div>
        reacTable
      </div>
      <div><em class=" photo-credit">Photo: Daniel Williams</em>
  </div>
  <notes>
    The reacTable[7] is another inspiration for Mesh Garden. It is an
    instrument with a tabletop user interface that allows players to create
    music by moving physical objects on top of a screen to manipulate
    musical parameters. Again, the non- portability of the table interface
    renders this inaccessible to a large group of people. The intention with
    Mesh Garden is to create something similar to these pieces, but using
    the all-pervasive and accessible smartphone.
  </notes>
  <div class="slide-count"></div>

  </div>
  <!-- <div>
    <div>Interactions</div>

    <notes>
      The interactions of Mesh Garden are designed to be intuitive for a
      non-musically trained player to use. Using the smartphone's compass, the
      piece allows the player to interact with the sounds. A player interacts
      by turning their phone, which affects two different parts of the work.
    </notes>
  </div> -->
  <!-- <div class=" layout" style="grid-template-rows: 75% 25%">
    <img src="images/mesh-garden/mesh garden player interaction.jpg" alt="" />
    <div>Relative axis compass interaction</div>
    <notes>
      <br />
      One aspect is turning on the relative axis. When the player logs on,
      their forward-facing position is registered to be zero degrees, which
      will produce the default sounds. Then, by turning the phone 90 degrees,
      180 degrees, and 270 degrees, the player can pick between four different
      pre- determined note options and rhythmic options made up of four
      different Euclidian rhythmic patterns. The rhythmic patterns are
      randomized for each player when they log on, but do not change after
      this point. Therefore, the player should be able to tell one pattern
      from another and use their musical intuition to choose the pattern that
      best ts musically.
      <br />
      To control the long bowed sound, the player can decide what order the
      line is played through. The choices are up, down, drunk, and random. The
      rhythm is based on the same Euclidian rhythms that determine onsets.
    </notes>
  </div> -->
  <!-- 
  <div class="layout" style="grid-template-rows: 75% 25%">
    <img src="images/mesh-garden/matching.jpg" alt="" />
    <div>Compass heading matching</div>
    <notes>
      The more active game play aspect of Mesh Garden is the compass heading
      matching feature. When a player matches with the headings of another
      player, the player that was moving last plays an unsynchronized melody.
      To tell if two phones are facing towards each other, the compass head-
      ings are compared. The absolute compass values are used instead of the
      relative orientation data of the other section. Each phone's heading is
      determined using the kompas npm library, then each heading is sent to
      the server. On the server, the headings are continually compared with
      each other. If the dierence between one player's head- ing and another's
      is 180 degrees, then the phones are facing each other. Once a match is
      found between two phones, a sound plays on one of the phones. The sound
      is one note of a melody that comes from a bank of pre-selected notes.
      This player then has the chance to take the note of the phone it matched
      with and add that note to its bank of notes. The phone that lost its
      note can then try to match with other phones to add their notes and
      build up its own melody. Since notes only get traded back and forth be-
      tween phones, they are never totally lost, rendering more of a creative
      orchestration between distributed devices.
    </notes>
  </div>
  <div>
    <div>Rhythmic synchronization with Ableton Link</div>

    <notes>
      Link is a technology developed by Ableton that allows any computers
      running Live to play in sync with each other. Because Link is open
      sourced, it is possible to use it in non- Live applications [2]. The
      Link API is in C++, a language not suitable for the web; so, to run Link
      in the web, I had to use a Node.js port, node-abletonlink, created by
      GitHub user 2bbb. This project ports the C++ Link implementation to
      Node.js to allow its use in the browser. Because of platform specific
      installation issues, Docker was needed to deploy Mesh Garden to a Linux
      server. I used Docker to ensure that the development and deployment
      environment were identical. By default, node-ableton link provides time
      based synchronization between devices but does not ensure that the
      synchronization is in metrical, musical time. Notes will all play at the
      same time, but the tempo will fluctuate due to network latency. To x
      this problem, I use the Trans- port system in Tone.js. When a player
      joins Mesh Garden, their device's rhythmic transport starts, giving
      their device a musically metronomic time clock. When a new player logs
      on, the system stops each of the other players trans- ports and then
      immediately restarts them, ensuring that all players stay in sync. I
      also use metrical quantization of time values in Tone.js to ensure that
      metronomic variation will be smoothed out by quantization on a
      synchronized clock. Used together, these methods create a successful
      distributed sequencer that works even with devices on separate networks.
    </notes>
  </div> -->
  <div class="layout" style="
        display: grid;
        grid-template-columns: repeat(4, 1fr);
        grid-template-rows: repeat(6, 1fr);
      ">
    <div style="grid-area: 1 / 1 / 2 / 5; justify-content: center;">
      <h1>Conclusions</h1>
    </div>
    <div style="grid-area: 2 / 1 / 5 / 5;">
      <ul>
        <li>Synchronization is difficult but useful</li>
        <li>Game dynamics open possibilities for participation</li>
        <li>
          More advanced interfaces needed for skilled musicians.
        </li>
      </ul>
    </div>
    <div class="slide-count"></div>

  </div>

  <!-- Sounds Aware -->
  <div class="layout"
    style="grid-template-rows: repeat(4, minmax(0, 1fr)); grid-template-columns: repeat(6, 1fr); gap: 10px;">
    <!-- Large hero image takes up most of the left side -->

    <!-- Title and descriptive text on the right -->
    <div style="grid-row: 1 / 2; grid-column: 1 / 4;">
      <span class="underline">Sounds Aware</span>
    </div>

    <!-- Exhibition details -->
    <div style="grid-row: 3 / 4; grid-column: 1/4;">
      Locative Audio Sound Art
    </div>

    <div style="grid-row: 1 / 4; grid-column: 4/ 7;">
      <img src="images/sounds-aware.png" />
    </div>


    <!-- Footer information spans full width -->
    <div style="grid-row: 4 / 5; grid-column: 1 / 3;">
      <span class="year">2019 — 2021</span>
    </div>
    <div style="grid-row: 4 / 5; grid-column: 3 / 7;">
      An app for sharing sound walks
    </div>

    <notes>
      After Mesh Garden, I became interested in leveraging the mobility of smartphones to create experiences designed
      for
      outdoor environments and walking. This led to Sounds Aware, a locative audio sound art project that fostered a
      shared
      experience of the environment through sound. Developed as an app, the project enabled users to share sound walks,
      creating a collective soundscape that reflected the diversity of their surroundings. Running from 2019 to 2021,
      Sounds
      Aware explored the potential of locative audio as a medium for crafting shared environmental experiences.
    </notes>
    <div class="slide-count"></div>

  </div>

  <div class="fancy-quote">
    <blockquote>

      To what extent might the technologies of communication, art and
      entertainment serve as 'prostheses' that would provide us with
      experiences of wilderness that would not only enrich our human
      identity but help us to preserve and expand the domain of the
      non-human world?

      <cite>
        David Dunn. Wilderness as Reentrant Form: Thoughts on the Future of
        Electronic Art and Nature. Leonardo, (4):377, 1988.
      </cite>
    </blockquote>
    <div style="text-align: right;">- David Dunn</div>

    <notes> Composer David Dunn poses an inspirational question: </notes>
    <div class="slide-count"></div>

  </div>

  <div>
    A goal of Sounds Aware is to shift attention to geophonic and biophonic
    soundscapes, away from the anthrophonony.

    <notes>
      The goal of Sounds Aware is to bring the user’s awareness to the
      geophonic and biophonic soundscape, which is often so masked by noise
      pollution that it has fallen out of awareness for many of us. Sounds
      Aware seeks to shift the user’s concept of nature to something that has
      no starting or end- ing point; it is all around us. The app brings
      awareness by focusing attention on the environment. Because of the pre-
      dominance of eye culture [3], our reliance on seeing rather than
      listening as a primary means of sensing the world, it is a lot to ask of
      a person who might be uninterested in acoustic ecology to “just listen”
      to their environment. But, if you give them a tool that urges listening
      in the quieter places, where the natural world will be more audible,
      there is a better chance of them engaging with those sounds because the
      app focused their perception. Sounds Aware is a means of technologically
      mediated “ear cleaning,” as described by R. Murray Schafer in Ear
      Cleaning: Notes for an Experimental Music Course [13].
    </notes>
    <div class="slide-count"></div>

  </div>

  <div class="layout" style="
        display: grid;
        grid-template-columns: repeat(4, 1fr);
        grid-template-rows: repeat(6, 1fr);
      ">
    <div style="grid-area: 1 / 1 / 2 / 5; justify-content: center;">
      <h1>Noise Pollution</h1>
    </div>
    <div style="grid-area: 2 / 1 / 5 / 5;">
      <ul>
        <li>
          There is overwhelming evidence that exposure to environmental noise
          has adverse effects on the health of the population.<cite>World Health Organization, Burden of disease from
            environmental
            noise: Quantification of healthy life years lost in Europe. World
            Health Organization. Regional Office for Europe, 2011.
          </cite>
        </li>
        <li>
          Sounds Aware will make users more aware of how much harmful noise
          they experience in their daily lives.
        </li>
      </ul>
    </div>
    <notes>A 2011 World Health Organization (WHO) report found that “there is
      overwhelming evidence that exposure to environmental noise has adverse
      effects on the health of the population [10].” Sounds Aware shifts a
      users attention away from noise pollution and to nature, which may help
      mitigate adverse health effects caused by noise pollution.
      <br />
      While a reduction in environmental noise at the source would be the best
      way to solve noise pollution, masking the noise is a stopgap solution. A
      masking solution has been implemented by several projects [9, 15] but
      not yet with a mobile device. Sounds Aware implements a similar idea but
      with a mobile phone.
    </notes>
    <div class="slide-count"></div>

  </div>


  <!-- immaterial.cloud -->
  <div class="layout"
    style="grid-template-rows: repeat(4, minmax(0, 1fr)); grid-template-columns: repeat(6, 1fr); gap: 10px;">
    <!-- Large hero image takes up most of the left side -->
    <div style="grid-row: 1 / 4; grid-column: 1 / 4;">
      <img src="images/immaterial.png" />
    </div>

    <!-- Title and descriptive text on the right -->
    <div style="grid-row: 1 / 2; grid-column: 4 / 7;">
      <span class="underline">immaterial.cloud</span>
    </div>

    <!-- Exhibition details -->
    <div style="grid-row: 3 / 4; grid-column: 4 / 7;">
      Collaborative Sound Art
    </div>

    <!-- Footer information spans full width -->
    <div style="grid-row: 4 / 5; grid-column: 1 / 3;">
      <span class="year">2020</span>
    </div>
    <div style="grid-row: 4 / 5; grid-column: 3 / 7;">
      peer-to-peer networking
    </div>

    <notes>
      For this project, I revisited the concept of collaborative music-making with smartphones, this time exploring the
      use of
      the phone's camera as a trigger for changes in sound. Networked smartphones formed a temporary sound art
      installation
      that could be set up anywhere, activating sound by flipping phones upward to allow the camera to detect movement.
      immaterial.cloud was a collaborative sound art project that harnessed peer-to-peer networking to create and share
      music.
      Designed as a collective experience, participants contributed to a shared soundscape, leveraging smartphone
      networking
      capabilities to facilitate a dynamic, interactive musical installation that transcended traditional boundaries of
      time
      and space.
    </notes>
    <div class="slide-count"></div>

  </div>

  <div class="layout" style="grid-template-rows: 75% 25%">
    <img src="images/immaterialcloud2.png" alt="immaterial.cloud" />
    <div>Participants interacting with the work</div>
    <notes>
      immaterial.cloud creates the opportunity for a shared space with
      participants by using technology in a collective way. It requires the
      phones to act together, and out of their hands, not as individuals as is
      usual in this era of personalized devices. Experiencing immaterial.cloud
      presents an opportunity for a restoration of attention that might have
      been lost by an overuse of technology in the typical way.

      <br />

      The concept for immaterial.cloud emerged as a way to create a communal
      experience during the COVID-19 shelter-in-place orders in which many
      people have turned to the internet for communication and entertainment.
      While social networks such as Facebook or Google seek our attention for
      profit, [immaterial.cloud](http://immaterial.cloud) seeks a deep
      attention that creates a shared sense of place and time for the
      participants.
    </notes>
    <div class="slide-count"></div>

  </div>
  <div class="layout" style="
        display: grid;
        grid-template-columns: repeat(4, 1fr);
        grid-template-rows: repeat(6, 1fr);
      ">
    <div style="grid-area: 1 / 1 / 2 / 5; justify-content: center;">
      <h1>Technical Description</h1>
    </div>
    <div style="grid-area: 2 / 1 / 5 / 5;">
      <ul>
        <li>Peer-to-peer networking in immaterial.cloud enables direct communication between phones, avoiding a central
          server and fostering a communal experience.</li>
        <li>immaterial.cloud uses WebRTC for real-time data transfer, facilitating direct streaming of audio and data
          between browsers without extra software.</li>
        <li>immaterial.cloud employs motion tracking using the phone's camera, where user movement triggers changes in
          the sound and sends that data to other devices on the network.</li>
      </ul>
    </div>
    <notes>
      [immaterial.cloud](http://immaterial.cloud) is a web application that
      uses peer-to-peer technologies to send data between phones without the
      need for an intermediary server. The [PeerJS](https://peerjs.com/)
      library is used to manage WebRTC connections to send data between
      phones. The application is hosted on [IPFS](https://ipfs.io/), a
      peer-to-peer hypermedia protocol, which removes the need for centralized
      server hosting. The participant interaction of waving a hand around in
      front of a phone to trigger changes is accomplished by using the phone's
      onboard camera and tracking motion. Each phone is assigned an ID along
      with one of four samples and presets so that when a participant waves in
      front of one specific phone it will have a predictable outcome.
    </notes>
    <div class="slide-count"></div>

  </div>

  <div class="layout" style="grid-template-rows: 75% 25%">
    <img src="images/immaterialcloud/qi5jxtMLvuyjoAfMFJ6onDzEUQptFfu8cggWfDfms3Q.png" alt="" />
    <a href="https://immaterial.cloud" target="blank">https://immaterial.cloud</a>

    <notes>
      This work needs 2-4 smartphones (iPhone or Android) connected to the
      internet via WiFi or a cellular network. All sound during the
      installation is played over the phones. A participant joins the network
      by going to <https: //immaterial.cloud> and entering the ID of a chosen
        "host" phone. No extra software is required to participate.
        immaterial.cloud will work with a group of participants or just one.
    </notes>
    <div class="slide-count"></div>

  </div>

  <div>
    <iframe title="vimeo-player" class="responsive-iframe azyload" src="https://player.vimeo.com/video/414630388"
      frameborder="0" allowfullscreen></iframe>
    <div class="slide-count"></div>

  </div>

  <!-- Resonant Landscapes -->
  <div class="layout"
    style="display: grid; grid-template-rows: repeat(4, 1fr); grid-template-columns: repeat(6, 1fr); gap: 10px;">
    <!-- Central image -->
    <div style="grid-row: 2 / 4; grid-column: 2 / 5;">
      <img src="images/frozen-lake.jpeg" style="width: 100%; height: 100%;" alt="Featured image" />
    </div>

    <!-- Surrounding text -->
    <div style="grid-row: 1 / 2; grid-column: 1 / 7;"><span class="underline">Resonant Landscapes</span></div>
    <div style="grid-row: 2 / 4; grid-column: 1 / 2;"><span class="year">2023-2024</span></div>
    <div style="grid-row: 2 / 4; grid-column: 5 / 7;">Locative Sound Art</div>
    <div style="grid-row: 4 / 5; grid-column: 1 / 3;">Ambisonic Field Recording</div>
    <div style="grid-row: 4 / 5; grid-column: 5 / 7;">GPS/Gyroscope</div>

    <notes>
      Resonant Landscapes is my most recent work, and it builds on the concepts explored in my previous projects. The
      piece
      uses ambisonic field recordings to create an immersive sound environment that responds to the listener's movement
      through space. By integrating GPS and gyroscope data from smartphones, the work transforms the listener's
      surroundings
      into a dynamic, interactive soundscape, inviting them to explore the sonic possibilities of their environment.
    </notes>
    <div class="slide-count"></div>

  </div>

  <div>

    <em><strong>Resonant Landscapes</strong></em> creates a <strong>hybrid place</strong>, merging natural
    soundscapes with urban spaces through <strong>ambisonic audio</strong> and GPS technology.

    <notes>
      Creating a Hybrid Place:

      - Locative Media: Maps state park coordinates onto DSU campus locations, creating a scaled geographical
      representation.
      - Ambisonic Audio: Plays immersive soundscapes when users approach designated spots.
      - Hybrid Soundscapes: Combines recorded nature sounds with real-time environmental sounds.
      - Body-Oriented Tracking: Uses smartphone sensors (GPS, gyroscope, accelerometer) for dynamic sound orientation.
      - Non-Representational Sound: Encourages immersion through abstract, non-representational soundscapes.

      Theoretical Influences:
      - Draws from sound art, soundwalking, and soundscape studies.
      - Resituates soundscapes in urban settings to encourage reflection on:
      - Ecological significance.
      - Cultural importance.
      - Relationship between sound, nature, and urban life.

      Experience & Impact:

      - Creates a "hybrid place" blending virtual and physical realities.
      - Induces a contemplative, reflective state, offering an escape from daily worries.
      - Challenges traditional notions of music and art through immersive, dynamic soundscapes.
    </notes>
    <div class="slide-count"></div>
  </div>

  <div class="layout" style="grid-template-rows: 75% 25%">
    <img src="images/rl-screenshots/me-carter.png" alt="">

    <div>Student Research</div>

    <notes>
      Resonant Landscapes was developed in collaboration with a student at Dakota State University. The project
      provided
      an opportunity to engage with cutting-edge technologies and explore the creative possibilities of
      locative sound art. Through their research and experimentation, my student contributed to the development of the
      app
      and helped shape its features.
    </notes>
    <div class="slide-count"></div>

  </div>

  <div class="layout" style="grid-template-rows: 75% 25%">
    <img src="images/rl-screenshots/sd-state-parks.png">
    <div>South Dakota State Parks</div>
    <div class="slide-count"></div>

  </div>
  <div class="layout" style="grid-template-rows: 75% 25%">
    <img src="images/rl-screenshots/uni-mi.png">
    <div>Resonant Landscapes @ UniMi</div>
    <div class="slide-count"></div>

  </div>
  <div class="layout" style="grid-template-rows: 75% 25%">
    <img src="images/rl-screenshots.png" alt="">

    <div>User Interactions</div>

    <notes>
      Here you can see a few screenshots of the app, a user finding a listening spot then activating body oriented
      tracking.
    </notes>
    <div class="slide-count"></div>

  </div>

  <div class="layout" style="
              grid-template-columns: repeat(4, 1fr);
              grid-template-rows: repeat(5, 1fr);
            ">
    <div style="grid-area: 1 / 1 / 3 / 6; justify-content: center">
      <h1>Audience Page</h1>
    </div>
    <div style="grid-area: 3 / 1 / 6 / 3">
      <img src="images/palisades.jpeg" width="100%" alt="" />
    </div>
    <div style="grid-area: 3 / 3 / 6 / 5">
      <ul>
        <li>Interactive campus map with listening spots</li>
        <li>Audio playback within a 15-meter radius</li>
        <li>Dynamic soundscapes based on user proximity</li>
        <li>Body-oriented tracking using smartphone sensors</li>
      </ul>
    </div>

    <notes>

    </notes>
    <div class="slide-count"></div>

  </div>

  <div class="layout" style="
                grid-template-columns: repeat(4, 1fr);
                grid-template-rows: repeat(5, 1fr);
              ">
    <div style="grid-area: 1 / 1 / 3 / 6; justify-content: center">
      <h1>Technical Details</h1>
    </div>
    <div style="grid-area:  3 / 1 / 6 / 3">
      <ul>
        <li>Core Audio OctoMic</li>
        <li>Web tech: React, Tailwind CSS, Resonance Audio SDK</li>
        <li>Smartphone sensors: GPS, gyroscope, accelerometer</li>

      </ul>
    </div>
    <div style="grid-area:3 / 3 / 6 / 5">
      <img src="images/octomic.jpg" width="100%" alt="" />
    </div>

    <notes>

    </notes>
    <div class="slide-count"></div>

  </div>

  <div class="layout">

    Resonant Landscapes Concert

    <notes>
      In addition to using the ambisonic recordings in the Resonant Landscapes app, DSU faculty and students composed
      works
      that premiered during a public concert at the Madison Area Arts Council.
    </notes>
    <div class="slide-count"></div>

  </div>


  <div class="layout">

    <img src="images/rl-concert/landscape-poster.png" alt="" width="100%" height="500px">

    <notes>
      In addition to using the ambisonic recordings in the Resonant Landscapes app, DSU faculty and students composed
      works
      that premiered during a public concert at the Madison Area Arts Council.
    </notes>
    <div class="slide-count"></div>

  </div>

  <div>

    <img src="images/rl-concert/me.png" alt="">

    <notes>
      In addition to using the ambisonic recordings in the Resonant Landscapes app, DSU faculty and students composed
      works
      that premiered during a public concert at the Madison Area Arts Council.
    </notes>
    <div class="slide-count"></div>

  </div>

  <div>
    <img src="images/rl-concert/daniel.png" alt="">

    <notes>
      In addition to using the ambisonic recordings in the Resonant Landscapes app, DSU faculty and students composed
      works
      that premiered during a public concert at the Madison Area Arts Council.
    </notes>
    <div class="slide-count"></div>

  </div>

  <div>

    <img src="images/rl-concert/kayla.png" alt="">

    <notes>
      In addition to using the ambisonic recordings in the Resonant Landscapes app, DSU faculty and students composed
      works
      that premiered during a public concert at the Madison Area Arts Council.
    </notes>
    <div class="slide-count"></div>

  </div>

  <div>

    <img src="images/rl-concert/jacob.png" alt="">

    <notes>
      In addition to using the ambisonic recordings in the Resonant Landscapes app, DSU faculty and students composed
      works
      that premiered during a public concert at the Madison Area Arts Council.
    </notes>
    <div class="slide-count"></div>

  </div>

  <div
    style="display: grid; grid-template-rows: repeat(4, minmax(0, 1fr)); grid-template-columns: repeat(6, 1fr); gap: 10px; height: 100vh;">
    <!-- Dominant visual element -->
    <div style="grid-row: 1 / 4; grid-column: 1 / 4;"><span class="underline">Veins of</span></div>
    <div style="grid-row: 2 / 3; grid-column: 1 / 4;"><span class="underline">the Earth</span></div>

    <!-- Information block -->
    <div style="grid-row: 3 / 4; grid-column: 4 / 7;">Fixed</div>

    <!-- Footer information -->
    <div style="grid-row: 4 / 5; grid-column: 4/7;">Media</div>
    <div style="grid-row: 4 / 5; grid-column: 1;"><span class="year">2024</span></div>

    <!-- Soundcloud Player -->
    <div class="soundcloud-embed" style="grid-row: 1 / 3; grid-column: 4 / 7; align-self: center;">
      <iframe width="100%" height="166" scrolling="no" frameborder="no" allow="autoplay"
        src="https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/1833817539&color=%233c7494&auto_play=false&hide_related=false&show_comments=true&show_user=true&show_reposts=false&show_teaser=true">
      </iframe>
    </div>
    <notes>
      The work I composed for this concert was
      a
      multi-channel fixed media piece, “Veins of the Earth,” which explores geophonic and biophonic sounds to evoke a
      sense of
      connection between natural environments and the
      life they sustain. This concert brought together the DSU and wider community to showcase the work of Digital Arts
      and
      Design students and faculty and promote engagement with the app.
    </notes>
    <div class="slide-count"></div>

  </div>


  <!-- Impact statement gets strong position at bottom -->
  <div
    style="display: grid; grid-template-rows: repeat(4, minmax(0, 1fr)); grid-template-columns: repeat(6, 1fr); gap: 0px; height: 100vh;">
    <!-- Large visual element -->
    <div style="grid-row: 1 / 3; grid-column: 1 / 4;">FUTURE </div>

    <!-- Contrasting text blocks -->
    <div style="grid-row: 1 / 2; grid-column: 3 / 7;">WORK</div>
    <div style="grid-row: 2 / 3; grid-column: 4 / 7;"><span class="underline">South Dakota Sound Archive</span></div>

    <!-- Information hierarchy -->
    <div style="grid-row: 3 / 5; grid-column: 1 / 3;"><span class="year">2025</span></div>
    <div style="grid-row: 3 / 4; grid-column: 3 / 7;">Student Work</div>
    <div style="grid-row: 4 / 5; grid-column: 3 / 7;">Community Engagement</div>
    <notes>
      My future research focuses on creating the DSU Digital Sound Archive, a project designed to capture the ecological
      soundscapes and cultural heritage of South Dakota and nearby regions. By integrating advanced field recording
      techniques
      and metadata, the archive will support interdisciplinary research across sound studies, ecology, and digital arts.
      A key
      component of the project is the Resonant Landscapes app, which uses GPS technology to overlay soundscapes onto
      physical
      locations, enhancing public engagement and ecological awareness. This initiative aligns with DSU's mission to
      expand
      research opportunities and foster collaboration across disciplines.
    </notes>
    <div class="slide-count"></div>

  </div>
  <div id="citations">
    <h2>References</h2>
    <div class="slide-count"></div>

  </div>

</body>

</html>